{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from experiment_utils import setup_experiment, train, evaluate_model\n",
    "from pruning import conduct_experiment\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "min_freqs = [2,20,80]\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']  # 5 distinct colors\n",
    "markers = ['o', 's', '^', 'D', '*']  # 5 different markers\n",
    "\n",
    "legends = {2: 'big', 20: 'medium', 80: 'small'}\n",
    "\n",
    "for dataset in ['reviews', 'imdb']:    \n",
    "    for model in ['bow_mlp']:\n",
    "        config = {\n",
    "                'batch_size': 32,\n",
    "                'seed': 42,\n",
    "                'num_epochs': 25,\n",
    "                'learning_rate': 1e-4,\n",
    "                'device': device,\n",
    "                'dataset_name': dataset,\n",
    "                'train_dir': 'Reviews.csv',\n",
    "                'test_dir': 'Reviews.csv',\n",
    "                'text_col': 'Text',\n",
    "                'label_col': 'Score',\n",
    "                'max_length': 256,\n",
    "                'num_classes': 5,\n",
    "                'model_type': model,\n",
    "                'model_size': 'small',\n",
    "                'optimizer_type': 'adam',\n",
    "            }\n",
    "        fig, ax = plt.subplots(2, 2, figsize=(9.2, 6.2), dpi=300)\n",
    "        #plt.subplots(2, 2, figsize=(3.544, 2.4), dpi=500\n",
    "        for min_freq, color, marker in zip(min_freqs, colors, markers):\n",
    "            config['min_freq']=min_freq\n",
    "            for wd in [0]:\n",
    "                torch.manual_seed(42)\n",
    "                (train_dataloader, test_dataloader), model = setup_experiment(config)\n",
    "                history = train(\n",
    "                    model=model,\n",
    "                    train_dataloader=train_dataloader,\n",
    "                    val_dataloader=test_dataloader,\n",
    "                    dataset_name=config['dataset_name'],\n",
    "                    model_type=config['model_type'],\n",
    "                    model_size=config['model_size'],\n",
    "                    num_epochs=config['num_epochs'],\n",
    "                    optimizer_type=config['optimizer_type'],\n",
    "                    lr=config['learning_rate'],\n",
    "                    weight_decay=wd,\n",
    "                    device=config['device'],\n",
    "                    save_path='./results/models'\n",
    "                )\n",
    "                for prune_emb in [False]:\n",
    "                    print('===================================')\n",
    "                    print('===================================')\n",
    "                    print(f\"MODEL: {config['model_type']}; DICT: {config['min_freq']}; PRUNE_EMB: {prune_emb}; WD: {wd}\")\n",
    "                    results_df = conduct_experiment(model, test_dataloader, config['dataset_name'], config['model_type'], config['model_size'],\n",
    "                                regime='linear_only', prune_embedding=prune_emb, device='cuda', save_path='results/metrics', \n",
    "                                weight_decay=wd, min_freq=min_freq, plot=False)\n",
    "                    # Plot results\n",
    "                    x_tr = results_df['threshold']\n",
    "                    y_ac = results_df['accuracy']\n",
    "                    y_fe = results_df['free_energy'][1:]\n",
    "                    x_den = results_df['sparsity']\n",
    "                    y_fe = (y_fe - y_fe.min()) / (y_fe.max() - y_fe.min())\n",
    "                    print(y_fe)\n",
    "                    \n",
    "                    # Plot 1: Accuracy vs Threshold\n",
    "                    ax[0, 0].plot(x_tr, y_ac, color=color, linewidth=1.5, marker=marker, markersize=6, label=f'vocab_size={legends[min_freq]}')\n",
    "                    \n",
    "                    # Plot 2: Accuracy vs Sparsity\n",
    "                    ax[0, 1].plot(x_den, y_ac, color=color, linewidth=1.5, marker=marker, markersize=6, label=f'vocab_size={legends[min_freq]}')\n",
    "                    \n",
    "                    # Plot 3: Free Energy vs Threshold\n",
    "                    ax[1, 0].plot(x_tr[1:], y_fe, color=color, linewidth=1.5, marker=marker, markersize=6, label=f'vocab_size={legends[min_freq]}')\n",
    "                    \n",
    "                    # Plot 4: Free Energy vs Sparsity\n",
    "                    ax[1, 1].plot(x_den[1:], y_fe, color=color, linewidth=1.5, marker=marker, markersize=6, label=f'vocab_size={legends[min_freq]}')\n",
    "                    \n",
    "                    \n",
    "        ax[0, 0].set_xlabel('Threshold', fontsize=12)\n",
    "        ax[0, 0].set_xlabel('Threshold', fontsize=12)\n",
    "        ax[0, 0].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "        ax[0, 0].grid(True, linestyle='--', alpha=0.5)\n",
    "        ax[0, 0].text(0.5, -0.3, '(a)', fontsize=12, ha='center', transform=ax[0, 0].transAxes)\n",
    "        ax[0, 0].legend()\n",
    "\n",
    "        ax[0, 1].set_xlabel('Sparsity', fontsize=12)\n",
    "        ax[0, 1].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "        ax[0, 1].grid(True, linestyle='--', alpha=0.5)\n",
    "        ax[0, 1].text(0.5, -0.3, '(c)', fontsize=12, ha='center', transform=ax[0, 1].transAxes)\n",
    "        ax[0, 1].legend()\n",
    "\n",
    "        ax[1, 0].set_xlabel('Threshold', fontsize=12)\n",
    "        ax[1, 0].set_ylabel('Free Energy', fontsize=12)\n",
    "        ax[1, 0].grid(True, linestyle='--', alpha=0.5)\n",
    "        ax[1, 0].text(0.5, -0.3, '(b)', fontsize=12, ha='center', transform=ax[1, 0].transAxes)\n",
    "        ax[1, 0].legend()\n",
    "\n",
    "        ax[1, 1].set_xlabel('Sparsity', fontsize=12)\n",
    "        ax[1, 1].set_ylabel('Free Energy', fontsize=12)\n",
    "        ax[1, 1].grid(True, linestyle='--', alpha=0.5)\n",
    "        ax[1, 1].text(0.5, -0.3, '(d)', fontsize=12, ha='center', transform=ax[1, 1].transAxes)\n",
    "        ax[1, 1].legend()\n",
    "\n",
    "        # Adjust spacing\n",
    "        plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "        plt.show() \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder-decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "min_freqs = [2,20,80]\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']  # 5 distinct colors\n",
    "markers = ['o', 's', '^', 'D', '*']  # 5 different markers\n",
    "\n",
    "shaded_regions = [\n",
    "    (0.32, 0.5),    # min_freq=2: sparsity range 0.2-0.4\n",
    "    (0.25, 0.4),   # min_freq=20: sparsity range 0.3-0.5\n",
    "    (0.10, 0.19)    # min_freq=80: sparsity range 0.6-0.8\n",
    "]\n",
    "\n",
    "for dataset in ['reviews']:\n",
    "    for prune_emb in [False, True]:    \n",
    "        for model in ['encoder_decoder']:\n",
    "            config = {\n",
    "                    'batch_size': 32,\n",
    "                    'seed': 42,\n",
    "                    'num_epochs': 25,\n",
    "                    'learning_rate': 1e-4,\n",
    "                    'device': device,\n",
    "                    'dataset_name': dataset,\n",
    "                    'train_dir': 'Reviews.csv',\n",
    "                    'test_dir': 'Reviews.csv',\n",
    "                    'text_col': 'Text',\n",
    "                    'label_col': 'Score',\n",
    "                    'max_length': 256,\n",
    "                    'num_classes': 5,\n",
    "                    'model_type': model,\n",
    "                    'model_size': 'small',\n",
    "                    'optimizer_type': 'adam',\n",
    "                }\n",
    "            fig, ax = plt.subplots(2, 2, figsize=(9.2, 6.2), dpi=300)\n",
    "            #plt.subplots(2, 2, figsize=(3.544, 2.4), dpi=500\n",
    "            for min_freq, color, marker, region in zip(min_freqs, colors, markers, shaded_regions):\n",
    "                config['min_freq']=min_freq\n",
    "                for wd in [0]:\n",
    "                    torch.manual_seed(42)\n",
    "                    (train_dataloader, test_dataloader), model = setup_experiment(config)\n",
    "                    history = train(\n",
    "                        model=model,\n",
    "                        train_dataloader=train_dataloader,\n",
    "                        val_dataloader=test_dataloader,\n",
    "                        dataset_name=config['dataset_name'],\n",
    "                        model_type=config['model_type'],\n",
    "                        model_size=config['model_size'],\n",
    "                        num_epochs=config['num_epochs'],\n",
    "                        optimizer_type=config['optimizer_type'],\n",
    "                        lr=config['learning_rate'],\n",
    "                        weight_decay=wd,\n",
    "                        device=config['device'],\n",
    "                        save_path='./results/models'\n",
    "                    )\n",
    "                    \n",
    "                    print('===================================')\n",
    "                    print('===================================')\n",
    "                    print(f\"MODEL: {config['model_type']}; DICT: {config['min_freq']}; PRUNE_EMB: {prune_emb}; WD: {wd}\")\n",
    "                    results_df = conduct_experiment(model, test_dataloader, config['dataset_name'], config['model_type'], config['model_size'],\n",
    "                                regime='linear_only', prune_embedding=prune_emb, device='cuda', save_path='results/metrics', \n",
    "                                weight_decay=wd, min_freq=min_freq, plot=False)\n",
    "                    # Plot results\n",
    "                    x_tr = results_df['threshold']\n",
    "                    y_ac = results_df['accuracy']\n",
    "                    y_fe = results_df['free_energy']\n",
    "                    x_den = results_df['sparsity']\n",
    "                    y_fe = results_df['free_energy'][1:]\n",
    "                    y_fe = (y_fe - y_fe.min()) / (y_fe.max() - y_fe.min())\n",
    "                    print(y_fe)\n",
    "                    \n",
    "                    ax[0, 0].plot(x_tr, y_ac, color=color, linewidth=1.5, marker=marker, markersize=6, label=f'vocab_size={legends[min_freq]}')\n",
    "                    \n",
    "                    # Plot 2: Accuracy vs Sparsity\n",
    "                    ax[0, 1].plot(x_den, y_ac, color=color, linewidth=1.5, marker=marker, markersize=6, label=f'vocab_size={legends[min_freq]}')\n",
    "                    \n",
    "                    # Plot 3: Free Energy vs Threshold\n",
    "                    ax[1, 0].plot(x_tr[1:], y_fe, color=color, linewidth=1.5, marker=marker, markersize=6, label=f'vocab_size={legends[min_freq]}')\n",
    "                    \n",
    "                    # Plot 4: Free Energy vs Sparsity\n",
    "                    ax[1, 1].plot(x_den[1:], y_fe, color=color, linewidth=1.5, marker=marker, markersize=6, label=f'vocab_size={legends[min_freq]}')\n",
    "                        \n",
    "                        \n",
    "            ax[0, 0].set_xlabel('Threshold', fontsize=12)\n",
    "            ax[0, 0].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "            ax[0, 0].grid(True, linestyle='--', alpha=0.5)\n",
    "            ax[0, 0].text(0.5, -0.3, '(a)', fontsize=12, ha='center', transform=ax[0, 0].transAxes)\n",
    "            ax[0, 0].legend()\n",
    "\n",
    "            ax[0, 1].set_xlabel('Sparsity', fontsize=12)\n",
    "            ax[0, 1].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "            ax[0, 1].grid(True, linestyle='--', alpha=0.5)\n",
    "            ax[0, 1].text(0.5, -0.3, '(c)', fontsize=12, ha='center', transform=ax[0, 1].transAxes)\n",
    "            ax[0, 1].legend()\n",
    "\n",
    "            ax[1, 0].set_xlabel('Threshold', fontsize=12)\n",
    "            ax[1, 0].set_ylabel('Free Energy', fontsize=12)\n",
    "            ax[1, 0].grid(True, linestyle='--', alpha=0.5)\n",
    "            ax[1, 0].text(0.5, -0.3, '(b)', fontsize=12, ha='center', transform=ax[1, 0].transAxes)\n",
    "            ax[1, 0].legend()\n",
    "\n",
    "            ax[1, 1].set_xlabel('Sparsity', fontsize=12)\n",
    "            ax[1, 1].set_ylabel('Free Energy', fontsize=12)\n",
    "            ax[1, 1].grid(True, linestyle='--', alpha=0.5)\n",
    "            ax[1, 1].text(0.5, -0.3, '(d)', fontsize=12, ha='center', transform=ax[1, 1].transAxes)\n",
    "            ax[1, 1].legend()\n",
    "\n",
    "            # Adjust spacing\n",
    "            plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "            plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "min_freqs = [2,20,80]\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']  # 5 distinct colors\n",
    "markers = ['o', 's', '^', 'D', '*']  # 5 different markers\n",
    "\n",
    "shaded_regions = [\n",
    "    (0.32, 0.5),    # min_freq=2: sparsity range 0.2-0.4\n",
    "    (0.25, 0.4),   # min_freq=20: sparsity range 0.3-0.5\n",
    "    (0.10, 0.19)    # min_freq=80: sparsity range 0.6-0.8\n",
    "]\n",
    "\n",
    "for dataset in ['reviews']:\n",
    "    for prune_emb in [False, True]:    \n",
    "        for model in ['encoder']:\n",
    "            config = {\n",
    "                    'batch_size': 32,\n",
    "                    'seed': 42,\n",
    "                    'num_epochs': 25,\n",
    "                    'learning_rate': 1e-4,\n",
    "                    'device': device,\n",
    "                    'dataset_name': dataset,\n",
    "                    'train_dir': 'Reviews.csv',\n",
    "                    'test_dir': 'Reviews.csv',\n",
    "                    'text_col': 'Text',\n",
    "                    'label_col': 'Score',\n",
    "                    'max_length': 256,\n",
    "                    'num_classes': 5,\n",
    "                    'model_type': model,\n",
    "                    'model_size': 'small',\n",
    "                    'optimizer_type': 'adam',\n",
    "                }\n",
    "            fig, ax = plt.subplots(2, 2, figsize=(9.2, 6.2), dpi=300)\n",
    "            #plt.subplots(2, 2, figsize=(3.544, 2.4), dpi=500\n",
    "            for min_freq, color, marker, region in zip(min_freqs, colors, markers, shaded_regions):\n",
    "                config['min_freq']=min_freq\n",
    "                for wd in [0]:\n",
    "                    torch.manual_seed(42)\n",
    "                    (train_dataloader, test_dataloader), model = setup_experiment(config)\n",
    "                    history = train(\n",
    "                        model=model,\n",
    "                        train_dataloader=train_dataloader,\n",
    "                        val_dataloader=test_dataloader,\n",
    "                        dataset_name=config['dataset_name'],\n",
    "                        model_type=config['model_type'],\n",
    "                        model_size=config['model_size'],\n",
    "                        num_epochs=config['num_epochs'],\n",
    "                        optimizer_type=config['optimizer_type'],\n",
    "                        lr=config['learning_rate'],\n",
    "                        weight_decay=wd,\n",
    "                        device=config['device'],\n",
    "                        save_path='./results/models'\n",
    "                    )\n",
    "                    \n",
    "                    print('===================================')\n",
    "                    print('===================================')\n",
    "                    print(f\"MODEL: {config['model_type']}; DICT: {config['min_freq']}; PRUNE_EMB: {prune_emb}; WD: {wd}\")\n",
    "                    results_df = conduct_experiment(model, test_dataloader, config['dataset_name'], config['model_type'], config['model_size'],\n",
    "                                regime='linear_only', prune_embedding=prune_emb, device='cuda', save_path='results/metrics', \n",
    "                                weight_decay=wd, min_freq=min_freq, plot=False)\n",
    "                    # Plot results\n",
    "                    x_tr = results_df['threshold']\n",
    "                    y_ac = results_df['accuracy']\n",
    "                    y_fe = results_df['free_energy']\n",
    "                    x_den = results_df['sparsity']\n",
    "                    y_fe = results_df['free_energy'][1:]\n",
    "                    y_fe = (y_fe - y_fe.min()) / (y_fe.max() - y_fe.min())\n",
    "                    print(y_fe)\n",
    "                    \n",
    "                    # Plot 1: Accuracy vs Threshold\n",
    "                    ax[0, 0].plot(x_tr, y_ac, color=color, linewidth=1.5, marker=marker, markersize=6, label=f'vocab_size={legends[min_freq]}')\n",
    "                    \n",
    "                    # Plot 2: Accuracy vs Sparsity\n",
    "                    ax[0, 1].plot(x_den, y_ac, color=color, linewidth=1.5, marker=marker, markersize=6, label=f'vocab_size={legends[min_freq]}')\n",
    "                    \n",
    "                    # Plot 3: Free Energy vs Threshold\n",
    "                    ax[1, 0].plot(x_tr[1:], y_fe, color=color, linewidth=1.5, marker=marker, markersize=6, label=f'vocab_size={legends[min_freq]}')\n",
    "                    \n",
    "                    # Plot 4: Free Energy vs Sparsity\n",
    "                    ax[1, 1].plot(x_den[1:], y_fe, color=color, linewidth=1.5, marker=marker, markersize=6, label=f'vocab_size={legends[min_freq]}')\n",
    "                        \n",
    "                        \n",
    "            ax[0, 0].set_xlabel('Threshold', fontsize=12)\n",
    "            ax[0, 0].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "            ax[0, 0].grid(True, linestyle='--', alpha=0.5)\n",
    "            ax[0, 0].text(0.5, -0.3, '(a)', fontsize=12, ha='center', transform=ax[0, 0].transAxes)\n",
    "            ax[0, 0].legend()\n",
    "\n",
    "            ax[0, 1].set_xlabel('Sparsity', fontsize=12)\n",
    "            ax[0, 1].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "            ax[0, 1].grid(True, linestyle='--', alpha=0.5)\n",
    "            ax[0, 1].text(0.5, -0.3, '(c)', fontsize=12, ha='center', transform=ax[0, 1].transAxes)\n",
    "            ax[0, 1].legend()\n",
    "\n",
    "            ax[1, 0].set_xlabel('Threshold', fontsize=12)\n",
    "            ax[1, 0].set_ylabel('Free Energy', fontsize=12)\n",
    "            ax[1, 0].grid(True, linestyle='--', alpha=0.5)\n",
    "            ax[1, 0].text(0.5, -0.3, '(b)', fontsize=12, ha='center', transform=ax[1, 0].transAxes)\n",
    "            ax[1, 0].legend()\n",
    "\n",
    "            ax[1, 1].set_xlabel('Sparsity', fontsize=12)\n",
    "            ax[1, 1].set_ylabel('Free Energy', fontsize=12)\n",
    "            ax[1, 1].grid(True, linestyle='--', alpha=0.5)\n",
    "            ax[1, 1].text(0.5, -0.3, '(d)', fontsize=12, ha='center', transform=ax[1, 1].transAxes)\n",
    "            ax[1, 1].legend()\n",
    "\n",
    "            # Adjust spacing\n",
    "            plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "            plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "min_freqs = [2,20,80]\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']  # 5 distinct colors\n",
    "markers = ['o', 's', '^', 'D', '*']  # 5 different markers\n",
    "\n",
    "shaded_regions = [\n",
    "    (0.32, 0.5),    # min_freq=2: sparsity range 0.2-0.4\n",
    "    (0.25, 0.4),   # min_freq=20: sparsity range 0.3-0.5\n",
    "    (0.10, 0.19)    # min_freq=80: sparsity range 0.6-0.8\n",
    "]\n",
    "\n",
    "for dataset in ['imdb']:\n",
    "    for prune_emb in [False, True]:    \n",
    "        for model in ['encoder']:\n",
    "            config = {\n",
    "                    'batch_size': 32,\n",
    "                    'seed': 42,\n",
    "                    'num_epochs': 25,\n",
    "                    'learning_rate': 1e-4,\n",
    "                    'device': device,\n",
    "                    'dataset_name': dataset,\n",
    "                    'train_dir': 'Reviews.csv',\n",
    "                    'test_dir': 'Reviews.csv',\n",
    "                    'text_col': 'Text',\n",
    "                    'label_col': 'Score',\n",
    "                    'max_length': 256,\n",
    "                    'num_classes': 5,\n",
    "                    'model_type': model,\n",
    "                    'model_size': 'small',\n",
    "                    'optimizer_type': 'adam',\n",
    "                }\n",
    "            fig, ax = plt.subplots(2, 2, figsize=(9.2, 6.2), dpi=300)\n",
    "            #plt.subplots(2, 2, figsize=(3.544, 2.4), dpi=500\n",
    "            for min_freq, color, marker, region in zip(min_freqs, colors, markers, shaded_regions):\n",
    "                config['min_freq']=min_freq\n",
    "                for wd in [0]:\n",
    "                    torch.manual_seed(42)\n",
    "                    (train_dataloader, test_dataloader), model = setup_experiment(config)\n",
    "                    history = train(\n",
    "                        model=model,\n",
    "                        train_dataloader=train_dataloader,\n",
    "                        val_dataloader=test_dataloader,\n",
    "                        dataset_name=config['dataset_name'],\n",
    "                        model_type=config['model_type'],\n",
    "                        model_size=config['model_size'],\n",
    "                        num_epochs=config['num_epochs'],\n",
    "                        optimizer_type=config['optimizer_type'],\n",
    "                        lr=config['learning_rate'],\n",
    "                        weight_decay=wd,\n",
    "                        device=config['device'],\n",
    "                        save_path='./results/models'\n",
    "                    )\n",
    "                    \n",
    "                    print('===================================')\n",
    "                    print('===================================')\n",
    "                    print(f\"MODEL: {config['model_type']}; DICT: {config['min_freq']}; PRUNE_EMB: {prune_emb}; WD: {wd}\")\n",
    "                    results_df = conduct_experiment(model, test_dataloader, config['dataset_name'], config['model_type'], config['model_size'],\n",
    "                                regime='linear_only', prune_embedding=prune_emb, device='cuda', save_path='results/metrics', \n",
    "                                weight_decay=wd, min_freq=min_freq, plot=False)\n",
    "                    # Plot results\n",
    "                    x_tr = results_df['threshold']\n",
    "                    y_ac = results_df['accuracy']\n",
    "                    y_fe = results_df['free_energy']\n",
    "                    x_den = results_df['sparsity']\n",
    "                    y_fe = results_df['free_energy'][1:]\n",
    "                    y_fe = (y_fe - y_fe.min()) / (y_fe.max() - y_fe.min())\n",
    "                    print(y_fe)\n",
    "                    \n",
    "                    # Plot 1: Accuracy vs Threshold\n",
    "                    ax[0, 0].plot(x_tr, y_ac, color=color, linewidth=1.5, marker=marker, markersize=6, label=f'min_freq={min_freq}')\n",
    "                    \n",
    "                    # Plot 2: Accuracy vs Sparsity\n",
    "                    ax[0, 1].plot(x_den, y_ac, color=color, linewidth=1.5, marker=marker, markersize=6, label=f'min_freq={min_freq}')\n",
    "                    \n",
    "                    # Plot 3: Free Energy vs Threshold\n",
    "                    ax[1, 0].plot(x_tr[1:], y_fe, color=color, linewidth=1.5, marker=marker, markersize=6, label=f'min_freq={min_freq}')\n",
    "                    \n",
    "                    # Plot 4: Free Energy vs Sparsity\n",
    "                    ax[1, 1].plot(x_den[1:], y_fe, color=color, linewidth=1.5, marker=marker, markersize=6, label=f'min_freq={min_freq}')\n",
    "\n",
    "                        \n",
    "                        \n",
    "            ax[0, 0].set_xlabel('Threshold', fontsize=12)\n",
    "            ax[0, 0].set_xlabel('Threshold', fontsize=12)\n",
    "            ax[0, 0].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "            ax[0, 0].grid(True, linestyle='--', alpha=0.5)\n",
    "            ax[0, 0].legend()\n",
    "\n",
    "            ax[0, 1].set_xlabel('Sparsity', fontsize=12)\n",
    "            ax[0, 1].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "            ax[0, 1].grid(True, linestyle='--', alpha=0.5)\n",
    "            ax[0, 1].legend()\n",
    "\n",
    "            ax[1, 0].set_xlabel('Threshold', fontsize=12)\n",
    "            ax[1, 0].set_ylabel('Free Energy', fontsize=12)\n",
    "            ax[1, 0].grid(True, linestyle='--', alpha=0.5)\n",
    "            ax[1, 0].legend()\n",
    "\n",
    "            ax[1, 1].set_xlabel('Sparsity', fontsize=12)\n",
    "            ax[1, 1].set_ylabel('Free Energy', fontsize=12)\n",
    "            ax[1, 1].grid(True, linestyle='--', alpha=0.5)\n",
    "            ax[1, 1].legend()\n",
    "\n",
    "            # Adjust spacing\n",
    "            plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "            plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from torch import nn\n",
    "warnings.filterwarnings('ignore')\n",
    "for dataset in ['imdb', 'reviews']:\n",
    "    for model in ['pretrained_transformer']:\n",
    "        config = {\n",
    "                'batch_size': 32,\n",
    "                'seed': 42,\n",
    "                'num_epochs': 10,\n",
    "                'learning_rate': 1e-4,\n",
    "                'device': device,\n",
    "                'dataset_name': dataset,\n",
    "                'train_dir': 'Reviews.csv',\n",
    "                'test_dir': 'Reviews.csv',\n",
    "                'text_col': 'Text',\n",
    "                'label_col': 'Score',\n",
    "                'max_length': 256,\n",
    "                'num_classes': 5,\n",
    "                'model_type': model,\n",
    "                'model_size': 'small',\n",
    "                'optimizer_type': 'adam',\n",
    "                'pretrained_model_name': \"huawei-noah/TinyBERT_General_4L_312D\"\n",
    "            }\n",
    "        for min_freq in [0]:\n",
    "            config['min_freq']=min_freq\n",
    "            for wd in [0]:\n",
    "                torch.manual_seed(42)\n",
    "                (train_dataloader, test_dataloader), model = setup_experiment(config)\n",
    "                model = model[0].to(device)\n",
    "                model.classifier = nn.Linear(model.bert.pooler.dense.out_features, 5)\n",
    "                history = train(\n",
    "                    model=model,\n",
    "                    train_dataloader=train_dataloader,\n",
    "                    val_dataloader=test_dataloader,\n",
    "                    dataset_name=config['dataset_name'],\n",
    "                    model_type=config['model_type'],\n",
    "                    model_size=config['model_size'],\n",
    "                    num_epochs=config['num_epochs'],\n",
    "                    optimizer_type=config['optimizer_type'],\n",
    "                    lr=config['learning_rate'],\n",
    "                    weight_decay=wd,\n",
    "                    device=config['device'],\n",
    "                    save_path='./results/models'\n",
    "                )\n",
    "                for prune_emb in [True]:\n",
    "                    print('===================================')\n",
    "                    print('===================================')\n",
    "                    print(f\"MODEL: {config['model_type']}; DICT: {config['min_freq']}; PRUNE_EMB: {prune_emb}; WD: {wd}\")\n",
    "                    conduct_experiment(model, test_dataloader, config['dataset_name'], config['model_type'], config['model_size'],\n",
    "                                regime='linear_only', prune_embedding=prune_emb, device='cuda', save_path='results/metrics', weight_decay=wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reproduction Cifar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn \n",
    "from torch.nn import functional as F\n",
    "from cv_models import * #importing all models\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "for model in ['mlp']:\n",
    "    config = {\n",
    "            'batch_size': 32,\n",
    "            'seed': 42,\n",
    "            'num_epochs': 25,\n",
    "            'learning_rate': 1e-4,\n",
    "            'device': device,\n",
    "            'dataset_name': 'cifar10',\n",
    "            #'train_dir': \"C:/Users/LEGION/Projects/codes + results-20250429T135614Z-001/aclImdb/aclImdb/train\",\n",
    "            #'test_dir': \"C:/Users/LEGION/Projects/codes + results-20250429T135614Z-001/aclImdb/aclImdb/test\",\n",
    "            #'text_col': 'Text',\n",
    "            #'label_col': 'Score',\n",
    "            'max_length': 256,\n",
    "            'num_classes': 5,\n",
    "            'model_type': model,\n",
    "            'model_size': 'small',\n",
    "            'optimizer_type': 'adam',\n",
    "        }\n",
    "    for min_freq in [0]:\n",
    "        config['min_freq']=min_freq\n",
    "        for wd in [0]:\n",
    "            torch.manual_seed(42)\n",
    "            (train_dataloader, test_dataloader), model = setup_experiment(config, load_model=False, model_path='./results/models\\cifar10_mlp_small_best.pth')\n",
    "            model = torch.load('./results/models/cifar10_mlp_small_best.pth', weights_only=False)['net'].to(device)\n",
    "            model.eval\n",
    "            for prune_emb in [False]:\n",
    "                print('===================================')\n",
    "                print('===================================')\n",
    "                print(f\"MODEL: {config['model_type']}; DICT: {config['min_freq']}; PRUNE_EMB: {prune_emb}; WD: {wd}\")\n",
    "                conduct_experiment(model, test_dataloader, config['dataset_name'], config['model_type'], config['model_size'],\n",
    "                            regime='linear_only', prune_embedding=prune_emb, device='cuda', save_path='results/metrics_2', weight_decay=wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "for model in ['pretrained_transformer']:\n",
    "    config = {\n",
    "            'batch_size': 32,\n",
    "            'seed': 42,\n",
    "            'num_epochs': 25,\n",
    "            'learning_rate': 1e-4,\n",
    "            'device': device,\n",
    "            'dataset_name': 'reviews',\n",
    "            'train_dir': 'Reviews.csv',\n",
    "            'test_dir': 'Reviews.csv',\n",
    "            'text_col': 'Text',\n",
    "            'label_col': 'Score',\n",
    "            'max_length': 256,\n",
    "            'num_classes': 5,\n",
    "            'model_type': model,\n",
    "            'model_size': 'small',\n",
    "            'optimizer_type': 'adam',\n",
    "            'pretrained_model_name': \"huawei-noah/TinyBERT_General_4L_312D\"\n",
    "        }\n",
    "    for min_freq in [2]:\n",
    "        config['min_freq']=min_freq\n",
    "        for wd in [0]:\n",
    "            torch.manual_seed(42)\n",
    "            (train_dataloader, test_dataloader), model = setup_experiment(config)\n",
    "            if config['model_type'] == 'pretrained_transformer':\n",
    "                model = model[0].to(device)\n",
    "            history = train(\n",
    "                model=model,\n",
    "                train_dataloader=train_dataloader,\n",
    "                val_dataloader=test_dataloader,\n",
    "                dataset_name=config['dataset_name'],\n",
    "                model_type=config['model_type'],\n",
    "                model_size=config['model_size'],\n",
    "                num_epochs=config['num_epochs'],\n",
    "                optimizer_type=config['optimizer_type'],\n",
    "                lr=config['learning_rate'],\n",
    "                weight_decay=wd,\n",
    "                device=config['device'],\n",
    "                save_path='./results/models'\n",
    "            )\n",
    "            start = time.time()\n",
    "            for prune_emb in [True]:\n",
    "                print('===================================')\n",
    "                print('===================================')\n",
    "                print(f\"MODEL: {config['model_type']}; DICT: {config['min_freq']}; PRUNE_EMB: {prune_emb}; WD: {wd}\")\n",
    "                conduct_experiment(model, test_dataloader, config['dataset_name'], config['model_type'], config['model_size'],\n",
    "                            regime='linear_only', prune_embedding=prune_emb, device='cuda', save_path='results/metrics_time_measurments', weight_decay=wd,\n",
    "                            accuracy_only=True, plot = False)\n",
    "                finish = time.time()\n",
    "                print(f\"Time taken for {config['model_type']}: {finish - start} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from torch import nn\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "for model in ['bow_mlp', 'encoder_decoder', 'encoder', 'pretrained_transformer']:\n",
    "    config = {\n",
    "            'batch_size': 32,\n",
    "            'seed': 42,\n",
    "            'num_epochs': 25,\n",
    "            'learning_rate': 1e-4,\n",
    "            'device': device,\n",
    "            'dataset_name': 'imdb',\n",
    "            'train_dir': 'aclImdb/aclImdb/train',\n",
    "            'test_dir': 'aclImdb/aclImdb/test',\n",
    "            'text_col': 'Text',\n",
    "            'label_col': 'Score',\n",
    "            'max_length': 256,\n",
    "            'num_classes': 5,\n",
    "            'model_type': model,\n",
    "            'model_size': 'small',\n",
    "            'optimizer_type': 'adam',\n",
    "            'pretrained_model_name': \"huawei-noah/TinyBERT_General_4L_312D\"\n",
    "        }\n",
    "    for min_freq in [2]:\n",
    "        config['min_freq']=min_freq\n",
    "        for wd in [0]:\n",
    "            torch.manual_seed(42)\n",
    "            (train_dataloader, test_dataloader), model = setup_experiment(config)\n",
    "            if config['model_type'] == 'pretrained_transformer':\n",
    "                model = model[0].to(device)\n",
    "                model.classifier = nn.Linear(model.classifier.in_features, config['num_classes'])\n",
    "            history = train(\n",
    "                model=model,\n",
    "                train_dataloader=train_dataloader,\n",
    "                val_dataloader=test_dataloader,\n",
    "                dataset_name=config['dataset_name'],\n",
    "                model_type=config['model_type'],\n",
    "                model_size=config['model_size'],\n",
    "                num_epochs=config['num_epochs'],\n",
    "                optimizer_type=config['optimizer_type'],\n",
    "                lr=config['learning_rate'],\n",
    "                weight_decay=wd,\n",
    "                device=config['device'],\n",
    "                save_path='./results/models'\n",
    "            )\n",
    "            start = time.time()\n",
    "            for prune_emb in [True]:\n",
    "                print('===================================')\n",
    "                print('===================================')\n",
    "                print(f\"MODEL: {config['model_type']}; DICT: {config['min_freq']}; PRUNE_EMB: {prune_emb}; WD: {wd}\")\n",
    "                conduct_experiment(model, test_dataloader, config['dataset_name'], config['model_type'], config['model_size'],\n",
    "                            regime='linear_only', prune_embedding=prune_emb, device='cuda', save_path='results/metrics_time_measurments_energy', weight_decay=wd,\n",
    "                            energy_only=True, plot = False)\n",
    "                finish = time.time()\n",
    "                print(f\"Time taken for {config['model_type']}: {finish - start} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
